{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_toc\"></a> \n",
    "## Tabla de Contenidos\n",
    "\n",
    "<a href=\"#section_intro\">Introducción</a>\n",
    "\n",
    "<a href='#section_dataset'>Datasets</a>\n",
    "\n",
    "<a href='#section_tipo'>Tipos de aprendizaje</a>\n",
    "\n",
    "<a href='#section_scikit'>Scikit-learn</a>\n",
    "\n",
    "- 3.1 <a href=\"#section_regresion\">Regresión</a>\n",
    "- 3.2 <a href=\"#section_clasificacion\">Clasificación</a>\n",
    "\n",
    "<a href=\"#section_resumen\">En resumen</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_intro\"></a> \n",
    "## Introducción a Machine Learning\n",
    "\n",
    "[volver a TOC](#section_toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando hablamos de *machine learning*, nos referimos al proceso mediante el cual **una computadora aprende a resolver una determinada tarea a partir de datos _sin que esté explícitamente programada para ello_**. \n",
    "\n",
    "Si bien muchas de las técnicas de aprendizaje automático existen hace ya varias décadas, en los últimos años se ha producido una verdadera explosión de estas tecnologías que ha determinado que múltiples aspectos de nuestra vida cotidiana estén totalmente permeados por el *machine learning*. \n",
    "\n",
    "Desde los sistemas de recomendación que nos sugieren qué película ver o qué artículo leer hasta las cámaras inteligentes que saben reconocer rostros en fotos de teléfonos celulares, pasando por detectores de spam en los servicios de e-mail y la publicidad dirigida en redes sociales, todas estas aplicaciones se desarrollan a partir de diversos algoritmos de *machine learning*.\n",
    "\n",
    "<div id=\"caja9\" style=\"float:left;width: 85%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/haciendo_foco.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label><u><i>Machine learning</i> pone el foco en la <b>predicción</b></u><br></label></div>   \n",
    "    \n",
    "Hasta el momento, siempre que hemos analizado datos, lo hicimos desde la *estadística descriptiva*, aquella que permite caracterizar los datos, y la *estadística inferencial*, que permite establecer conclusiones acerca de los parámetros de una población a partir de estimadores muestrales. \n",
    "    \n",
    "Las técnicas de *machine learning*, en cambio, típicamente se enmarcan dentro del ámbito de la **estadística predictiva**. \n",
    "    \n",
    "El aprendizaje automático entra en juego cuando **los algoritmos procesan datos de entrada y se adaptan a ellos para construir un modelo que represente su comportamiento general.** Una vez que estos modelos han sido *ajustados* a datos observados previamente, pueden ser usados para *predecir* y entender aspectos de los datos nuevos.\n",
    "\n",
    "Mientras que estos métodos pueden ser increíblemente poderosos, para ser efectivos deben utilizarse con un sólido conocimiento de las fortalezas y debilidades de cada uno, para lo cual es imprescindible tener un entendimiento general de algunos **conceptos claves**, como los de *sesgo y varianza, subajuste y sobreajuste, parámetros e hiperparámetros y validación cruzada*, entre otros. \n",
    "    \n",
    "Esta notebook será nuestro primer contacto con el *machine learning*: aparecerán muchos conceptos nuevos sobre los que iremos profundizando más adelante, pero con los que es conveniente ir ganando cierta familiaridad, ya que nos acompañarán en todas las clases de ahora en más.\n",
    "    \n",
    "Comenzaremos distinguiendo los distintos tipos de aprendizaje posibles y luego introduciremos la biblioteca **Scikit-Learn**, el paquete por excelencia - aunque no el único - para trabajar con algoritmos de *machine learning* con Python. Mostraremos algunas aplicaciones sencillas de los distintos tipos de problemas que podemos resolver con estas herramientas y presentaremos la metodología y el flujo de trabajo típicos en un proyecto de *machine learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_dataset\"></a> \n",
    "## Datasets\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En los primeros dos Módulos del curso, estuvimos incorporando conceptos y herramientas para analizar los datos. Aprendimos a usar *Python*, a conocer sus *estructuras de datos*.\n",
    "\n",
    "Al recibir un dataset, vimos como *\"limpiar\"* los datos recibidos, hacerles *data wrangling*, con el fin de generar un dataset apto para ser analizado.\n",
    "\n",
    "Luego sí realizamos el análisis exploratorio de los datos, usando tanto la *estadística descriptiva*, como la *estadística inferencial*, con el fin de comprender el contenido del dataset.\n",
    "\n",
    "<img src=\"img/M3_CLASE_18_proceso_dataset.png\" align=\"center\" alt=\"proceso_dataset\" width=80% height=50% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora pensemos el dataset validado y analizado como una tabla de datos, o como se dice en la jerga, un *tablón*.\n",
    "\n",
    "<img src=\"img/M3_CLASE_18_dataset.png\" align=\"center\" alt=\"diferencias\" width=70% height=40% />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Las muestras u **observaciones** (*filas*) refieren a objetos individuales descritos por el dataset.\n",
    "\n",
    "Las **features** (*columnas*) referencian características de las muestras. Por convención, el conjunto o matriz de features se suele referenciar con una variable llamada “X”. Se asume que la matriz de features tiene forma [n_samples, m_features], y frecuentemente se almacena como un array de Numpy o un DataFrame de Pandas.\n",
    "\n",
    "En muchos casos, una feature, tiene un significado especial. Representa un valor que clasifica a cada observación. Por convención se la indica como “y”. Y también como variable *target u objetivo* porque puede ser predicha a partir de las otras features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_tipo\"></a> \n",
    "## Tipos de aprendizaje\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A grandes rasgos, podemos distinguir dos tipos de aprendizaje automático: el aprendizaje *supervisado* y el aprendizaje *no supervisado*. La diferencia entre ambos radica en la **existencia o no de una variable objetivo** para predecir, respectivamente.\n",
    "\n",
    "####  Aprendizaje supervisado\n",
    "\n",
    "Los algoritmos de aprendizaje supervisado se encargan de **asociar características o *features* de las observaciones a una determinada variable *target***. Si la variable objetivo es una **variable continua**, como podrían ser el precio del metro cuadrado de una propiedad o el producto bruto interno de un país, se trata de un problema de **regresión**. Si, por el contrario, la variable objetivo es una **variable categórica**, como podría ser el caso de los tags de spam o no spam de un correo electrónico, nos encontramos ante un caso de **clasificación**.\n",
    "\n",
    "La supervisión del aprendizaje se produce en el momento en que comparamos las predicciones del modelo con los valores reales que se buscan predecir. Dependiendo del tipo de problema, existen distintas **métricas de *performance*** que podemos computar para saber cuán acertadas fueron las predicciones.\n",
    "\n",
    "####  Aprendizaje no supervisado\n",
    "\n",
    "A diferencia de lo que ocurre en el caso de los algoritmos de regresión o clasificación, el aprendizaje no supervisado **se caracteriza por prescindir de una variable *target*. El foco está puesto en descubrir patrones o estructuras subyacentes en la información que nos permitan generar *insights* relevantes en una estructura de datos que, a priori, no son evidentes.** Dentro del aprendizaje no supervisado, se engloban las técnicas de ***clustering*** y las de **reducción de la dimensionalidad**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_scikit\"></a> \n",
    "## Scikit-learn\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/sklearn.png\" width=\"300\">\n",
    "<br>\n",
    "\n",
    "Hay varias bibliotecas de Python que proveen sólidas implementaciones de muchos de algoritmos de _machine learning_. Una de las más difundidas es **Scikit-Learn**, un paquete que provee implementaciones eficientes de un gran número de los algoritmos más usados a través de una interfaz estándar y consistente.\n",
    "\n",
    "Durante el curso, veremos varios ejemplos de aplicación de métodos usando esta biblioteca.\n",
    "\n",
    "Todavía no entraremos en demasiado detalle teórico sobre los distintos modelos, pero este primer contacto nos permitirá ilustrar la metodología de trabajo para generar modelos usando Scikit-learn.\n",
    "\n",
    "### Documentación\n",
    "https://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuRbYNZlYqb9"
   },
   "source": [
    "<a id=\"section_regresion\"></a>\n",
    "### Regresión\n",
    "\n",
    "Como ejemplo de este proceso, vamos a considerar una regresión lineal simple, es decir, el caso común de ajustar una recta a datos de la forma $(x, y)$, donde $x$ es la única _feature_ que caracteriza a una observación e $y$, el valor de la variable objetivo asocidada.\n",
    "\n",
    "El modelo asume que hay una relación aproximadamente lineal entre $x$ e $y$, que podemos expresar matemáticamente como\n",
    "\n",
    "$$ y_i \\approx \\beta_0 + \\beta_1 x_{i1}. $$\n",
    "\n",
    "De acuerdo a esta ecuación, decimos que regresamos $y$ a partir de $x$. $\\beta_0$ y $\\beta_1$ son los coeficientes o parámetros desconocidos que representan la ordenada al origen y la pendiente del modelo lineal, respectivamente.  \n",
    "\n",
    "La tarea consiste en estimar los valores de $\\beta_0$ y $\\beta_1$ que permitan hacer una predicción de $y$ a partir de un valor conocido de $x$. Una vez que ajustamos el modelo a nuestros datos, obtenemos los estimadores $\\hat{\\beta_0}$ y $\\hat{\\beta_1}$, con los que podemos predecir $y$ a partir de cualquier valor de $x$, simplemente computando\n",
    "\n",
    "$$ \\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} x_{i1}. $$\n",
    "\n",
    "Para ejemplificar la regresión lineal simple, vamos a utilizar el dataset de publicidad presentado en el manual [An Introduction to Statistical Learning with Applications in R](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf) de James, Witten, Hastie y Tibshirani (2013).\n",
    "\n",
    "Primero importamos las librerías necesarias para trabajar con datos y visualizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset de publicidad para nuestro ejemplo de regresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising = pd.read_csv('../Data/Advertising.csv')\n",
    "advertising.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a observar las primeras 5 filas de nuestro dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las primeras tres columnas representan los gastos de publicidad en miles de USD en diferentes medios (TV, radio y diarios). Estas tres columnas constituyen nuestras _features_.\n",
    "\n",
    "La cuarta columna representa las ventas de un determinado producto en miles de unidades de la empresa que invierte en publicidad. Esta va a ser nuestra variable _target_.\n",
    "\n",
    "**Nuestro objetivo será predecir la cantidad de ventas a partir de la inversión en publicidad en los diferentes medios**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos los datos haciendo un *pair plot*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(advertising);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos la matriz de correlación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(advertising.corr(), annot=True, vmin=-1, cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nuestro primer objetivo es hacer un modelo de regresión simple, es decir con una sola feature, vamos a elegir la variable TV, ya que es la que muestra una correlación mayor con nuestra variable objetivo.\n",
    "\n",
    "Vamos a hacer un _scatter plot_ entre TV y Sales. El método `regplot()` de Seaborn genera un gráfico que, además de los datos, también nos va a mostrar la recta que se obtiene con una regresión lineal simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.regplot(advertising.TV, advertising.Sales, order=1, ci=None, scatter_kws={'color':'r', 's':9})\n",
    "sns.regplot(data = advertising, x = \"TV\", y = \"Sales\", order=1, ci=None, scatter_kws={'color':'r', 's':9})\n",
    "plt.xlim(-10,310)\n",
    "plt.ylim(bottom=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Cómo se interpreta esta recta?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder conocer qué valores adoptan $\\hat{\\beta_0}$ y $\\hat{\\beta_1}$, necesitamos ajustar un modelo de regresión lineal simple a los datos. Para ello, utilizaremos Scikit-Learn y seguiremos una serie de pasos que marcan el flujo de trabajo típico:\n",
    "\n",
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/kit_de_salida.png\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>1. Seleccionar una clase de modelo<br>\n",
    "                                             2. Elegir los hiperparámetros del modelo<br>\n",
    "                                             3. Preparar los datos en una matriz de <i>features</i> y un vector <i>target</i><br>\n",
    "                                             4. Separar los sets de entrenamiento y de testeo<br>\n",
    "                                             5. Ajustar el modelo a los datos de entrenamiento<br>\n",
    "                                             6. Predecir etiquetas para datos desconocidos<br>\n",
    "      7. Evaluar la <i>performance</i> del modelo</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OE8y9bRmYqcQ"
   },
   "source": [
    "##### **1. Seleccionar una clase de modelo**\n",
    "\n",
    "En Scikit-Learn, cada clase de modelo se representa con una clase de Python. La biblioteca está cuidadosamente estructurada en módulos, de forma tal que cada clase o función se encuentre en un módulo específico que engloba clases o funciones de la misma familia. Entonces, por ejemplo, si queremos trabajar con un modelo de regresión lineal, podemos importar la clase de regresión lineal de esta forma del módulo correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p47YawORYqcT"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iaAM1BxkYqcg"
   },
   "source": [
    "`LinearRegression` constituye una clase de **estimador** particular. Notar que también existen otros modelos de regresión lineal más generales. Podés leer más acerca de ellos en la [documentación del módulo `linear_model`](http://Scikit-Learn.org/stable/modules/linear_model.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kH9o-ilTYqcj"
   },
   "source": [
    "##### **2. Elegir los hiperparámetros del modelo**\n",
    "\n",
    "Es importante destacar que **una clase de modelo no es lo mismo que una instancia de modelo**.\n",
    "\n",
    "Una vez que hemos decidido nuestra clase de modelo, todavía tenemos que tomar algunas decisiones. Dependiendo de la clase de modelo con la que trabajemos, podríamos tener que responder a una o más preguntas como las siguientes:\n",
    "\n",
    "- ¿Queremos incluir también un intercepto (`intercept = True`)?\n",
    "- ¿Queremos que el modelo esté normalizado?\n",
    "- ¿Queremos agregar features calculados a partir del input para darle mayor flexibilidad al modelo?\n",
    "- ¿Qué grado de regularización vamos a querer usar en el modelo?\n",
    "\n",
    "Estos son ejemplos de las importantes decisiones que deben hacerse una vez que hemos seleccionado la clase de modelo a usar.\n",
    "\n",
    "Estas elecciones se representan frecuentemente como **hiperparámetros**, o parámetros que deben ser seteados antes de que el modelo sea ajustado a los datos. Una misma clase de modelo con dos configuraciones de hiperparámetros distintas puede llevar a resultados muy disímiles entre sí.\n",
    "\n",
    "En Scikit-Learn, los hiperparámetros son elegidos como argumentos en la instanciación del modelo. Exploraremos cómo podemos justificar cuantitativamente la elección de hiperparámetros en las próximas clases.\n",
    "\n",
    "Para nuestro ejemplo de regresión lineal, podemos instanciar la clase `LinearRegression` y especificar que nos gustaría ajustar el intercepto seteando a `True` el hiperparámetro `fit_intercept`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VtBY8okYqcl"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ru1vC6pdYqcy"
   },
   "source": [
    "**Tener en cuenta**: cuando el modelo es instanciado, la única acción que sucede es almacenar los valores de los hiperparámetros.\n",
    "\n",
    "En concreto, todavía no hemos ajustado el modelo a ningún dato: la API de Scikit-Learn hace una **distinción muy clara entre la _elección del modelo con sus hiperparámetros_ y el _ajuste del modelo a los datos_**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeUi31e6Yqc0"
   },
   "source": [
    "##### **3. Preparar los datos en una matriz de _features_ y un vector _target_**\n",
    "\n",
    "Nosotros queremos predecir el valor de Sales a partir del valor de gastos publicitarios en TV. Para que nos sirvan como *input* de un determinado algoritmo, habrá que representarlos correctamente. Scikit-Learn requiere que los datos de entrada sean representados como **una matriz de _features_ de dos dimensiones y un vector _target_ de una dimensión**. La matriz de _features_ puede ser un array 2D de Numpy o un `DataFrame` de Pandas, mientras que el vector objetivo puede ser un array 1D de Numpy o una `Series` de Pandas.\n",
    "\n",
    "A continuación, creamos la matriz de _features_ (a la que llamaremos $X$ por convención) y el vector _target_ ($y$), que utilizaremos para ajustar nuestro modelo de regresión lineal simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boNeWZy9Yqc3"
   },
   "outputs": [],
   "source": [
    "# Creamos X e y\n",
    "feature_cols = ['TV']\n",
    "X = advertising[feature_cols]\n",
    "y = advertising.Sales\n",
    "\n",
    "# Corrobaros la shape y el tipo de cada una\n",
    "print(\"Shape X:\", X.shape)\n",
    "print(\"Type X:\", type(X))\n",
    "print(\"Shape y:\", y.shape)\n",
    "print(\"Type y:\", type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/haciendo_foco.png\" style=\"align:center\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>Por más de que $X$ contenga una única variable, aun así debemos tratarla como un objeto bidimensional por los requerimientos de representación de datos propios de Scikit-Learn.</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4. Separar los sets de entrenamiento y de testeo**\n",
    "\n",
    "Sabemos que para que nuestro modelo pueda predecir, debe aprender primero a partir de los datos. Será importante poder evaluar qué tan buenas resultan sus predicciones, comparándolas con los valores reales que se buscan predecir. Si bien esta evaluación puede hacerse sobre los mismos datos con los que ajustamos nuestro modelo, también sería deseable tener una noción acerca de cómo se comporta frente a datos nunca antes vistos. Después de todo, el interés real de cualquier modelo de _machine learning_ radica en poder hacer predicciones de variables relevantes que nos son desconocidas ($y$) a partir de un conjunto de información con la que sí contamos ($X$).\n",
    "\n",
    "La pregunta es, entonces, ¿cómo generamos estos datos nunca antes vistos por el modelo? Una opción sería recolectar nuevas muestras y utilizar nuestro modelo para hacer predicciones de nuestra variable de interés, $y$, a partir de los atributos de cada muestra, $X$. Pero si desconocemos el verdadero valor de $y$, ¿cómo podemos evaluar las predicciones?\n",
    "\n",
    "Para resolver este problema, vamos a dividir los datos en un _training set_ y un _testing set_. El modelo aprenderá a partir de los datos del _training set_ y, luego del entrenamiento, predecirá valores de $y$ a partir de observaciones de la $X$ del conjunto de _testing set_, que luego serán contrastadas con los valores reales de las $y$ de testeo.\n",
    "\n",
    "Esto podría hacerse a mano, pero es más conveniente usar la función `train_test_split()`, que importaremos del módulo de [`model_selection`](https://scikit-learn.org/stable/model_selection.html) de Scikit-Learn, el cual contiene herramientas para la selección y evaluación de modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split()` debe recibir como argumento un objeto bidimensional $X$, un objeto unidimensional $y$, a partir de los cuales devuelve dos matrices matrices de _features_ y dos vectores *target*, correspondientes a los conjuntos de entrenamiento y testeo, respectivamente. Notar que el orden es relevante, por lo que tendremos que prestar atención a la asignación de los retornos de la función. Con una sintaxis similar a la de _unpacking_ de listas o tuplas, podemos hacer una correcta asignación en una única línea de código:\n",
    "\n",
    "```python\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)\n",
    "```\n",
    "\n",
    "Por defecto, la separación de las observaciones se hace al azar (`shuffle=True`), de forma tal de trabajar con un muestreo aleatorio. Para poder controlar esta aleatoriedad, podemos establecer con el argumento `random_state` una semilla (equivalente al `seed` de Numpy). Optativamente, también podemos regular el tamaño de cada set de datos con los argumentos `train_size` o `test_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Qué inconvenientes podrían surgir de no aleatorizar los datos que son asignados a los conjuntos de entrenamiento y testeo?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q21g2iZ1YqdC"
   },
   "source": [
    "##### **5. Ajustar el modelo a los datos de entrenamiento**\n",
    "\n",
    "Ahora es momento de que nuestro modelo aprenda a partir de los datos de entrenamiento. Esto puede hacerse con el método ``fit()`` de nuestra instancia de modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3tOYqLgYqdI"
   },
   "outputs": [],
   "source": [
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El verbo _fit_ puede traducirse como _ajustar_ o *entrenar*, por lo que nos referiremos indistintamente al proceso de aprendizaje propio del _machine learning_ con cualquiera de estos dos términos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2OeIS1SfYqdU"
   },
   "source": [
    "El método ``fit()`` realiza una secuencia de cómputos internos dependientes del modelo, y los resultados de estas operaciones son almacenadas en atributos específicos de la clase de modelo que el usuario luego puede explorar.\n",
    "\n",
    "En Scikit-learn, por convención, todos los atributos que representan los parámetros de los modelos que fueron aprendidos durante el proceso de entrenamiento con ``fit()`` se identifican por tener guiones bajo (*underscores*) luego de sus nombres. Por ejemplo, en este modelo lineal, podemos verificar los valores de $\\hat{\\beta_0}$ y $\\hat{\\beta_1}$ aprendidos inspeccionando los atributos `intercept_` y `coef_`, respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPr1EOQyYqdX"
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DneceQuzYqdm"
   },
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_T0MJG2Yqdv"
   },
   "source": [
    "Estos dos parámetros representan la pendiente y el intercepto del ajuste lineal simple a los datos.\n",
    "\n",
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Cómo interpretamos a estos valores? ¿Qué relación tienen con el gráfico que veíamos anteriormente?</b></label></div>\n",
    "</div>\n",
    "\n",
    "Una pregunta que surge frecuentemente se relaciona con incertidumbre o incerteza (*uncertainty*) en estos parámetros internos del modelo. \n",
    "\n",
    "En general, Scikit-Learn no provee herramientas para obtener conclusiones del estado interno de los modelos: interpretar los parámetros de un modelo tiene mucho más que ver con una pregunta de _modelado estadístico_ que con una pregunta de _machine learning_.\n",
    "\n",
    "_Machine learning_ se enfoca en la calidad con la cual el modelo _predice_.\n",
    "\n",
    "Si te interesa investigar el significado de los parámetros de ajuste dentro del modelo, existen otras herramientas, incluyendo el paquete de Python [Statsmodels](http://statsmodels.sourceforge.net/), con las que estaremos trabajando más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JH9QcMk0Yqdz"
   },
   "source": [
    "##### **6. Predecir etiquetas para datos desconocidos**\n",
    "\n",
    "Una vez que el modelo ya está entrenado, la principal tarea en el aprendizaje supervisado es evaluarlo en base a lo que dice acerca de nuevos datos que no fueron parte del _training set_. \n",
    "\n",
    "En Scikit-Learn, esto puede hacerse usando el método ``predict()``.\n",
    "\n",
    "Para ganar intuición, empecemos aplicando la fórmula $ \\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} x_{i1} $ manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JyvB5Lj0Yqd2"
   },
   "outputs": [],
   "source": [
    "# Aplicando la fórmula manualmente\n",
    "test = 200\n",
    "model.intercept_ + model.coef_*test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A partir de un valor conocido en gasto en publicidad en TV de 200 miles de dólares, nuestro modelo estima que un total de ventas aproximado de 16,52 mil unidades**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando el método del objeto\n",
    "test_sklearn = np.array(test).reshape(-1,1)\n",
    "model.predict(test_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Por qué es necesario el paso del reshape()?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTa7-0VoYqeI"
   },
   "source": [
    "Podemos calcular y asignar a una variable las predicción del modelo para todas las observaciones en el set de testeo usando el método ``predict()`` de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRCRFoTTYqeN"
   },
   "outputs": [],
   "source": [
    "ypred = model.predict(Xtest)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Qué significan estos valores?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **7. Evaluar la _performance_ del modelo**\n",
    "\n",
    "Finalmente, vamos a  evaluar el desempeño del modelo comparando las predicciones con los valores reales. A continuación, presentamos algunas de las métricas más utilizadas para la evaluación de un modelo de regresión:\n",
    "\n",
    "El **error absoluto medio** (_Mean Absolut Error_ o MAE) es la media del valor absoluto de los errores:\n",
    "\n",
    "$$ \\frac 1n\\sum_ {i = 1}^n |y_i-\\hat{y}_i| $$\n",
    "\n",
    "El **error cuadrático medio** (_Mean Squared Error_ o MSE) es la media de los errores al cuadrado:\n",
    "\n",
    "$$ \\frac 1n\\sum_ {i = 1}^n(y_i- \\hat{y}_i)^2 $$\n",
    "\n",
    "El **error cuadrático medio raíz** (_Root Mean Squared Error_ o RMSE) es la raíz cuadrada de la media de los errores al cuadrado:\n",
    "\n",
    "$$ \\sqrt{\\frac 1n\\sum_{i = 1}^n(y_i- \\hat{y}_i)^2} $$\n",
    "\n",
    "El **$R^2$** es la proporción de la varianza total de $y$ explicada por el modelo.\n",
    "\n",
    "Comparando estas métricas:\n",
    "\n",
    "- _MAE_ es el error promedio.\n",
    "- _MSE_ \"penaliza\" errores grandes, de ahí que eleve los valores al cuadrado.\n",
    "- _RMSE_ es comparable con la variable objetivo, ya que tiene las mismas unidades que la $y$.\n",
    "- _$R^2$_ es la proporción de la varianza total de $y$ explicada por el modelo\n",
    "\n",
    "Con excepción del $R^2$, todas éstas son **funciones de pérdida**, porque queremos **minimizarlas**. El $R^2$, por su parte, cuanto más próximo a 1 se encuentre, mejor.\n",
    "\n",
    "En el [módulo de métricas](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) de Scikit-Learn podemos hallar funciones específicas para evaluar la _performance_ de un modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-u6QckgYqeb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "print ('MAE:', mean_absolute_error(ytest, ypred).round(2))\n",
    "print ('MSE:', mean_squared_error(ytest, ypred).round(2))\n",
    "print ('RMSE:', np.sqrt(mean_squared_error(ytest, ypred)).round(2))\n",
    "print ('R2:', r2_score(ytest, ypred).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/haciendo_foco.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>Los métodos de evaluación requieren como argumento los valores reales y los predichos (en ese orden).</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la clases que vienen vamos a estudiar en profundidad el modelo de regresión lineal, tanto en su versión simple como múltiple. Más adelante en el curso también trabajaremos con otras técnicas de regresión no lineales, como los árboles de regresión y los ensambles de regresión, que constituyen algunos de los algoritmos del _state of the art_ de _machine learning_.\n",
    "\n",
    "Pasemos ahora a analizar un ejemplo sencillo de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_resumen\"></a> \n",
    "## En resumen\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La biblioteca **Scikit-Learn** es el paquete fundamental para trabajar con algoritmos de _machine learning_ con Python. A partir de esta clase, será nuestra principal herramienta de trabajo. Continuaremos profundizando en ella a lo largo de todo el curso.\n",
    "\n",
    "Pero es importante que recordemos el flujo de trabajo que presentamos en esta notebook, ya que nos acompañará de ahora en más:\n",
    "\n",
    "<br>\n",
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/kit_de_salida.png\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>1. Seleccionar una clase de modelo<br>\n",
    "                                             2. Elegir los hiperparámetros del modelo<br>\n",
    "                                             3. Preparar los datos en una matriz de <i>features</i> y un vector <i>target</i><br>\n",
    "                                             4. Separar los sets de entrenamiento y de testeo<br>\n",
    "                                             5. Ajustar el modelo a los datos de entrenamiento<br>\n",
    "                                             6. Predecir etiquetas para datos desconocidos<br>\n",
    "      7. Evaluar la <i>performance</i> del modelo</b></label></div>\n",
    "</div>\n",
    "\n",
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/ponete_a_prueba.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>Ahora que conocés de qué se tratan los problemas de regresión y clasificación, ¿te imaginás algún caso en que podrías aplicar estas técnicas?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
